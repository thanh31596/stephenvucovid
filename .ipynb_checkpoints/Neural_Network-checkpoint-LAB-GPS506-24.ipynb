{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# <font color=red> Neural Networks </font>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd \n",
    "import numpy as np \n",
    "from stephentools import get_file\n",
    "from stephentools import data_d3\n",
    "from stephentools import analyse_feature_importance\n",
    "from stephentools import visualize_decision_tree\n",
    "from sklearn.metrics import r2_score\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "from sklearn.metrics import classification_report, accuracy_score\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.metrics import roc_auc_score\n",
    "\n",
    "from sklearn.metrics import roc_curve"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = get_file()\n",
    "df,X,y,X_train, X_test, y_train, y_test=data_d3()\n",
    "rs=42"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Build a Neural Network model using the default setting. Answer the following: "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### a. Explain the parameters in the model: Network architecture, iterations, activation functions..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train accuracy: 0.8561190738699008\n",
      "Test accuracy: 0.7970330411328388\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "       False       0.85      0.82      0.84       940\n",
      "        True       0.71      0.75      0.73       543\n",
      "\n",
      "    accuracy                           0.80      1483\n",
      "   macro avg       0.78      0.79      0.78      1483\n",
      "weighted avg       0.80      0.80      0.80      1483\n",
      "\n",
      "MLPClassifier(activation='relu', alpha=0.0001, batch_size='auto', beta_1=0.9,\n",
      "              beta_2=0.999, early_stopping=False, epsilon=1e-08,\n",
      "              hidden_layer_sizes=(100,), learning_rate='constant',\n",
      "              learning_rate_init=0.001, max_iter=200, momentum=0.9,\n",
      "              n_iter_no_change=10, nesterovs_momentum=True, power_t=0.5,\n",
      "              random_state=42, shuffle=True, solver='adam', tol=0.0001,\n",
      "              validation_fraction=0.1, verbose=False, warm_start=False)\n"
     ]
    }
   ],
   "source": [
    "model_1 = MLPClassifier(random_state=rs)\n",
    "model_1.fit(X_train, y_train)\n",
    "\n",
    "print(\"Train accuracy:\", model_1.score(X_train, y_train))\n",
    "print(\"Test accuracy:\", model_1.score(X_test, y_test))\n",
    "\n",
    "y_pred = model_1.predict(X_test)\n",
    "print(classification_report(y_test, y_pred))\n",
    "\n",
    "print(model_1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ True,  True, False, ..., False, False,  True])"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_pred"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Fine Tune Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(3628, 166)\n"
     ]
    }
   ],
   "source": [
    "print(X_train.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## <font color='red'>Model 1<font/>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "GridSearchCV(cv=10, error_score='raise-deprecating',\n",
       "             estimator=MLPClassifier(activation='relu', alpha=0.0001,\n",
       "                                     batch_size='auto', beta_1=0.9,\n",
       "                                     beta_2=0.999, early_stopping=False,\n",
       "                                     epsilon=1e-08, hidden_layer_sizes=(100,),\n",
       "                                     learning_rate='constant',\n",
       "                                     learning_rate_init=0.001, max_iter=200,\n",
       "                                     momentum=0.9, n_iter_no_change=10,\n",
       "                                     nesterovs_momentum=True, power_t=0.5,\n",
       "                                     random_state=42, shuffle=True,\n",
       "                                     solver='adam', tol=0.0001,\n",
       "                                     validation_fraction=0.1, verbose=False,\n",
       "                                     warm_start=False),\n",
       "             iid='warn', n_jobs=-1,\n",
       "             param_grid={'activation': ['tanh'],\n",
       "                         'hidden_layer_sizes': [(100,), (120,), (140,), (160,),\n",
       "                                                (180,)],\n",
       "                         'solver': ['lbfgs']},\n",
       "             pre_dispatch='2*n_jobs', refit=True, return_train_score=True,\n",
       "             scoring=None, verbose=0)"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "params = {'hidden_layer_sizes': [(x,) for x in range(100, 200, 20)],'activation':['tanh'],'solver':['lbfgs']}\n",
    "\n",
    "cv_1 = GridSearchCV(param_grid=params, estimator=MLPClassifier(random_state=rs),return_train_score=True, cv=10, n_jobs=-1)\n",
    "cv_1.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "result_set = cv_1.cv_results_\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train accuracy: 0.7894156560088202\n",
      "Test accuracy: 0.7916385704652731\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "       False       0.79      0.91      0.85       940\n",
      "        True       0.79      0.59      0.68       543\n",
      "\n",
      "    accuracy                           0.79      1483\n",
      "   macro avg       0.79      0.75      0.76      1483\n",
      "weighted avg       0.79      0.79      0.78      1483\n",
      "\n",
      "{'activation': 'tanh', 'hidden_layer_sizes': (120,), 'solver': 'lbfgs'}\n"
     ]
    }
   ],
   "source": [
    "print(\"Train accuracy:\", cv_1.score(X_train, y_train))\n",
    "print(\"Test accuracy:\", cv_1.score(X_test, y_test))\n",
    "\n",
    "y_pred = cv_1.predict(X_test)\n",
    "print(classification_report(y_test, y_pred))\n",
    "\n",
    "print(cv_1.best_params_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total number of models:  5\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "train_result = result_set['split0_train_score']\n",
    "test_result = result_set['split0_test_score']\n",
    "print(\"Total number of models: \", len(test_result))\n",
    "# plot hidden layers hyperparameter values vs training and test accuracy score\n",
    "plt.plot(range(0, len(train_result)), train_result, 'b', range(0,len(test_result)), test_result, 'r')\n",
    "plt.xlabel('Hyperparameter Hidden_layers\\nBlue = training acc. Red = test acc.')\n",
    "plt.title('Optimal with TANH activation method')\n",
    "plt.xticks(range(0, len(train_result)),range(5, 86, 20))\n",
    "plt.ylabel('score')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## <font color='red'>Model 2<font/>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train accuracy: 0.8497794928335171\n",
      "Test accuracy: 0.7835468644639245\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "       False       0.84      0.81      0.83       940\n",
      "        True       0.69      0.73      0.71       543\n",
      "\n",
      "    accuracy                           0.78      1483\n",
      "   macro avg       0.77      0.77      0.77      1483\n",
      "weighted avg       0.79      0.78      0.78      1483\n",
      "\n",
      "{'hidden_layer_sizes': (145,), 'max_iter': 700}\n"
     ]
    }
   ],
   "source": [
    "# new parameters\n",
    "params = {'hidden_layer_sizes': [(x,) for x in range(130, 160, 15)], 'max_iter':[700,800,900]}\n",
    "\n",
    "cv_2 = GridSearchCV(param_grid=params, estimator=MLPClassifier(random_state=rs), cv=10, n_jobs=-1)\n",
    "cv_2.fit(X_train, y_train)\n",
    "\n",
    "print(\"Train accuracy:\", cv_2.score(X_train, y_train))\n",
    "print(\"Test accuracy:\", cv_2.score(X_test, y_test))\n",
    "\n",
    "y_pred = cv_2.predict(X_test)\n",
    "print(classification_report(y_test, y_pred))\n",
    "\n",
    "print(cv_2.best_params_)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## <font color='red'>Model 3<font/>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train accuracy: 0.8583241455347299\n",
      "Test accuracy: 0.7909642616318274\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "       False       0.83      0.84      0.84       940\n",
      "        True       0.72      0.70      0.71       543\n",
      "\n",
      "    accuracy                           0.79      1483\n",
      "   macro avg       0.78      0.77      0.77      1483\n",
      "weighted avg       0.79      0.79      0.79      1483\n",
      "\n",
      "{'alpha': 0.001, 'hidden_layer_sizes': (145,)}\n"
     ]
    }
   ],
   "source": [
    "#3rd\n",
    "params = {'hidden_layer_sizes': [(x,) for x in range(145, 180, 20)], 'alpha': [0.01,0.001, 0.0001, 0.00001]}\n",
    "\n",
    "cv_3 = GridSearchCV(param_grid=params, estimator=MLPClassifier(random_state=rs), cv=10, n_jobs=-1)\n",
    "cv_3.fit(X_train, y_train)\n",
    "\n",
    "print(\"Train accuracy:\", cv_3.score(X_train, y_train))\n",
    "print(\"Test accuracy:\", cv_3.score(X_test, y_test))\n",
    "\n",
    "y_pred = cv_3.predict(X_test)\n",
    "print(classification_report(y_test, y_pred))\n",
    "\n",
    "print(cv_3.best_params_)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## <font color='red'>Model 4<font/>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cv_4.fit(X_train, y_train)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "print(\"Train accuracy:\", cv_4.score(X_train, y_train))\n",
    "print(\"Test accuracy:\", cv_4.score(X_test, y_test))\n",
    "\n",
    "y_pred = cv_4.predict(X_test)\n",
    "print(classification_report(y_test, y_pred))\n",
    "\n",
    "print(cv_4.best_params_)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## <font color='red'>Model 5<font/>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train accuracy: 0.8241455347298787\n",
      "Test accuracy: 0.7956844234659474\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "       False       0.81      0.89      0.85       940\n",
      "        True       0.77      0.63      0.69       543\n",
      "\n",
      "    accuracy                           0.80      1483\n",
      "   macro avg       0.79      0.76      0.77      1483\n",
      "weighted avg       0.79      0.80      0.79      1483\n",
      "\n",
      "MLPClassifier(activation='tanh', alpha=0.0001, batch_size='auto', beta_1=0.9,\n",
      "              beta_2=0.999, early_stopping=False, epsilon=1e-08,\n",
      "              hidden_layer_sizes=145, learning_rate='constant',\n",
      "              learning_rate_init=0.001, max_iter=700, momentum=0.9,\n",
      "              n_iter_no_change=10, nesterovs_momentum=True, power_t=0.5,\n",
      "              random_state=42, shuffle=True, solver='lbfgs', tol=0.0001,\n",
      "              validation_fraction=0.1, verbose=False, warm_start=False)\n"
     ]
    }
   ],
   "source": [
    "model_5 = MLPClassifier(hidden_layer_sizes=145, max_iter=700, solver='lbfgs', random_state=42, activation='tanh')\n",
    "model_5.fit(X_train, y_train)\n",
    "\n",
    "print(\"Train accuracy:\", model_5.score(X_train, y_train))\n",
    "print(\"Test accuracy:\", model_5.score(X_test, y_test))\n",
    "\n",
    "y_pred = model_5.predict(X_test)\n",
    "print(classification_report(y_test, y_pred))\n",
    "\n",
    "print(model_5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Train accuracy: 0.8255237045203969\n",
    "Test accuracy: 0.8105192178017532"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "0.8996692392502756\n",
    "Test accuracy: 0.7997302764666218\n",
    "    iter 200 hidden 165"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Train accuracy: 0.9807056229327453\n",
    "Test accuracy: 0.8010788941335132\n",
    "    iter 700 Hidden 165"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train accuracy: 0.9798787210584344\n",
      "Test accuracy: 0.7936614969656103\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "       False       0.82      0.86      0.84       940\n",
      "        True       0.74      0.68      0.71       543\n",
      "\n",
      "    accuracy                           0.79      1483\n",
      "   macro avg       0.78      0.77      0.77      1483\n",
      "weighted avg       0.79      0.79      0.79      1483\n",
      "\n",
      "MLPClassifier(activation='tanh', alpha=0.0001, batch_size='auto', beta_1=0.9,\n",
      "              beta_2=0.999, early_stopping=False, epsilon=1e-08,\n",
      "              hidden_layer_sizes=145, learning_rate='constant',\n",
      "              learning_rate_init=0.001, max_iter=700, momentum=0.9,\n",
      "              n_iter_no_change=10, nesterovs_momentum=True, power_t=0.5,\n",
      "              random_state=42, shuffle=True, solver='adam', tol=0.0001,\n",
      "              validation_fraction=0.1, verbose=False, warm_start=False)\n"
     ]
    }
   ],
   "source": [
    "model_2 = MLPClassifier(hidden_layer_sizes=145, max_iter=700, solver='adam', random_state=42, activation='tanh')\n",
    "model_2.fit(X_train, y_train)\n",
    "\n",
    "print(\"Train accuracy:\", model_2.score(X_train, y_train))\n",
    "print(\"Test accuracy:\", model_2.score(X_test, y_test))\n",
    "\n",
    "y_pred = model_2.predict(X_test)\n",
    "print(classification_report(y_test, y_pred))\n",
    "\n",
    "print(model_2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Select with Decision Tree"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DecisionTreeClassifier(class_weight=None, criterion='gini', max_depth=17,\n",
      "                       max_features=None, max_leaf_nodes=None,\n",
      "                       min_impurity_decrease=0.0, min_impurity_split=None,\n",
      "                       min_samples_leaf=20, min_samples_split=2,\n",
      "                       min_weight_fraction_leaf=0.0, presort=False,\n",
      "                       random_state=42, splitter='best')\n"
     ]
    }
   ],
   "source": [
    "import pickle\n",
    "with open('DT.pickle', 'rb') as f:\n",
    "    dt_best,roc_index_dt_best, fpr_dt_best, tpr_dt_best = pickle.load(f)\n",
    "\n",
    "print(dt_best)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "covid19_symptoms : 0.3441404242821123\n",
      "income_med : 0.18735999132581302\n",
      "worried : 0.10684367064060209\n",
      "working_travel critical : 0.05893549513836796\n",
      "health_worker : 0.029681197797928313\n",
      "house_count : 0.028700386981849273\n",
      "insurance : 0.023567387237388056\n",
      "risk_mortality : 0.022105521176654413\n",
      "race_white : 0.021172434763189578\n",
      "weight : 0.019046383166260582\n",
      "contacts_count : 0.017111972739106446\n",
      "covid19_contact : 0.01633985712469371\n",
      "height : 0.015814759630596104\n",
      "age_70_80 : 0.011635449823777757\n",
      "age_60_70 : 0.01103832427484473\n",
      "immigrant : 0.010870020919422537\n",
      "country_BR : 0.010800754351478778\n",
      "age_20_30 : 0.00917021340207108\n",
      "country_US : 0.008079498762168525\n",
      "age_40_50 : 0.0077680328706121425\n"
     ]
    }
   ],
   "source": [
    "analyse_feature_importance(dt_best, X.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(3628, 21)\n"
     ]
    }
   ],
   "source": [
    "from sklearn.feature_selection import SelectFromModel\n",
    "\n",
    "selectmodel = SelectFromModel(dt_best, prefit=True)\n",
    "X_train_sel_model = selectmodel.transform(X_train)\n",
    "X_test_sel_model = selectmodel.transform(X_test)\n",
    "\n",
    "print(X_train_sel_model.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'X_train_sel_model' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-41-def20a82a4b3>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      2\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[0mcv_sel_model\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mGridSearchCV\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mparam_grid\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mparams\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mestimator\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mMLPClassifier\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mrandom_state\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mrs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcv\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m10\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mn_jobs\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;33m-\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 4\u001b[1;33m \u001b[0mcv_sel_model\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX_train_sel_model\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my_train\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      5\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      6\u001b[0m \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"Train accuracy:\"\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcv_sel_model\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mscore\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX_train_sel_model\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my_train\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'X_train_sel_model' is not defined"
     ]
    }
   ],
   "source": [
    "params = {'hidden_layer_sizes': (165,), 'alpha': [0.01,0.001, 0.0001, 0.00001]}\n",
    "\n",
    "cv_sel_model = GridSearchCV(param_grid=params, estimator=MLPClassifier(random_state=rs), cv=10, n_jobs=-1)\n",
    "cv_sel_model.fit(X_train_sel_model, y_train)\n",
    "\n",
    "print(\"Train accuracy:\", cv_sel_model.score(X_train_sel_model, y_train))\n",
    "print(\"Test accuracy:\", cv_sel_model.score(X_test_sel_model, y_test))\n",
    "\n",
    "y_pred = cv_sel_model.predict(X_test_sel_model)\n",
    "print(classification_report(y_test, y_pred))\n",
    "\n",
    "print(cv_sel_model.best_params_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "MLPClassifier(activation='relu', alpha=0.0001, batch_size='auto', beta_1=0.9,\n",
       "              beta_2=0.999, early_stopping=False, epsilon=1e-08,\n",
       "              hidden_layer_sizes=(100,), learning_rate='constant',\n",
       "              learning_rate_init=0.001, max_iter=700, momentum=0.9,\n",
       "              n_iter_no_change=10, nesterovs_momentum=True, power_t=0.5,\n",
       "              random_state=42, shuffle=True, solver='adam', tol=0.0001,\n",
       "              validation_fraction=0.1, verbose=False, warm_start=False)"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_6 = MLPClassifier(random_state=42, max_iter=700)\n",
    "model_6.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train accuracy: 0.8616317530319736\n",
      "Test accuracy: 0.799055967633176\n"
     ]
    }
   ],
   "source": [
    "print(\"Train accuracy:\", model_6.score(X_train, y_train))\n",
    "print(\"Test accuracy:\", model_6.score(X_test, y_test))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ROC "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ROC index on test for NN_default: 0.8688139179499236\n",
      "ROC index on test for NN_default: 0.8519650483915209\n",
      "ROC index on test for NN_default: 0.8448904823478705\n",
      "ROC index on test for NN_default: 0.8542122173896007\n",
      "ROC index on test for NN_default: 0.8524803103326671\n",
      "ROC index on test for NN_default: 0.8490243329023158\n",
      "ROC index on test for NN_default: 0.8670761333803534\n"
     ]
    }
   ],
   "source": [
    "y_pred_proba_nn_1 = model_1.predict_proba(X_test)\n",
    "y_pred_proba_nn_2 = model_2.predict_proba(X_test)\n",
    "y_pred_proba_nn_3 = cv_1.predict_proba(X_test)\n",
    "y_pred_proba_nn_4 = cv_2.predict_proba(X_test)\n",
    "y_pred_proba_nn_5 = cv_3.predict_proba(X_test)\n",
    "y_pred_proba_nn_6 = model_5.predict_proba(X_test)\n",
    "y_pred_proba_nn_7 = model_6.predict_proba(X_test)\n",
    "\n",
    "\n",
    "roc_index_nn_1 = roc_auc_score(y_test, y_pred_proba_nn_1[:, 1])\n",
    "roc_index_nn_2 = roc_auc_score(y_test, y_pred_proba_nn_2[:, 1])\n",
    "roc_index_nn_3 = roc_auc_score(y_test, y_pred_proba_nn_3[:, 1])\n",
    "roc_index_nn_4 = roc_auc_score(y_test, y_pred_proba_nn_4[:, 1])\n",
    "roc_index_nn_5 = roc_auc_score(y_test, y_pred_proba_nn_5[:, 1])\n",
    "roc_index_nn_6 = roc_auc_score(y_test, y_pred_proba_nn_6[:, 1])\n",
    "roc_index_nn_7 = roc_auc_score(y_test, y_pred_proba_nn_7[:, 1])\n",
    "\n",
    "print(\"ROC index on test for NN_default:\", roc_index_nn_1)\n",
    "print(\"ROC index on test for NN_default:\", roc_index_nn_2)\n",
    "print(\"ROC index on test for NN_default:\", roc_index_nn_3)\n",
    "print(\"ROC index on test for NN_default:\", roc_index_nn_4)\n",
    "print(\"ROC index on test for NN_default:\", roc_index_nn_5)\n",
    "print(\"ROC index on test for NN_default:\", roc_index_nn_6)\n",
    "print(\"ROC index on test for NN_default:\", roc_index_nn_7)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
